<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">



<title>An Analysis of a Weight Lifting Exercise Dataset</title>

<script src="project_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="project_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="project_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="project_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="project_files/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="project_files/highlight/default.css"
      type="text/css" />
<script src="project_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>
<div class="container-fluid main-container">

<!-- tabsets -->
<script src="project_files/navigation/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">


<h1 class="title">An Analysis of a Weight Lifting Exercise Dataset</h1>

</div>


<p>Joseph Stein - 3/6/2016</p>
<div id="executive-summary" class="section level2">
<h2>Executive Summary</h2>
<p>In this study, six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different ways: class A is the correct way, while classes B-E are incorrect ways. The goal is to predict which class the subject falls into based on various accelerometer data collected by wearable devices. Because this is a categorical problem, I chose to apply a Random Forest machine learning algorithm with 3-fold cross-validation to predict the manner in which subjects performed the weight-lifting exercise. The model uses 53 unique covariates that are both non-sparse in nature and which show sufficient variance to be meaningful.</p>
<p>Based on the confusion matrix results when applying the model to a validation set, the algorithm does a good job at predicting class based on a validation dataset with an accuracy of &gt;90%.</p>
<p>Source: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a></p>
</div>
<div id="covariate-determination" class="section level2">
<h2>Covariate Determination</h2>
<p>Once the data was loaded into R, initial data exploration was performed. Specific covariates were then chosen for the model, based on various techniques.</p>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## Warning: package &#39;caret&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Warning: package &#39;lattice&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.1.3</code></pre>
<pre class="r"><code>library(ggplot2)
insample &lt;- read.csv(&#39;C:/Users/Joseph/Desktop/MOOC/coursera/data_science/c8_machine_learning/project/pml-training.csv&#39;)</code></pre>
<p>The distribution of classes within the raw dataset appears to be reasonably equal, although class A (the correct way to perform the exercise) has the most observations</p>
<pre class="r"><code>table(insample$classe)</code></pre>
<pre><code>## 
##    A    B    C    D    E 
## 5580 3797 3422 3216 3607</code></pre>
<p>To begin the process of covariate selection, I first removed columns from the data frame that are not relevant to model construction. These include sequential observation counts as well as various timestamps taken from the wearable devices. I then isolated and removed near-zero variance predictors from the data frame.</p>
<p>Initial dimensions of the data:</p>
<pre><code>## [1] 19622   160</code></pre>
<p>After summarizing the processed data, it appeared that several predictor candidates contained sparse data. To keep the model simple, I decided to remove all predictors where the % of NA exceeded 95%. This further reduced the dimensionality of the data, and brought down the total number of predictors to 53.</p>
<pre class="r"><code>sumna&lt;-numeric(0)
for (i in 1:ncol(insample)) {
        sumna[i]&lt;-sum(is.na(insample[,i])==TRUE)/nrow(insample)
}
insample&lt;-insample[,sumna&lt;0.95]</code></pre>
<p>Final dimensions of the data:</p>
<pre><code>## [1] 19622    53</code></pre>
</div>
<div id="model-construction" class="section level2">
<h2>Model Construction</h2>
<p>The approach I chose was to use Random Forest with 3-fold cross validation. The pros of Random Forest for classification prediction is accuracy and the fact that it can handle non-linear associations. However, the cons of Random Forest include reduced speed, reduced interpretability, as well as the potential for overfitting. While a relatively small number of folds were used for cross-validation (in this case, K=3), the overall performance variance was less â€“ although at the expense of increased bias.</p>
<p>Before fitting a model, I partitioned the insample dataset into both a training dataset and a validation dataset. I chose to do this to 1) reduce the time required to build a model and 2) to get a sense of the accuracy of the model prior to applying it to a test set.</p>
<pre class="r"><code>inbuild &lt;- createDataPartition(y=insample$classe,p=0.7,list=FALSE)
train &lt;- insample[inbuild,]
validate &lt;- insample[-inbuild,]

modFit &lt;-train(classe~.,data=train,method=&quot;rf&quot;,trControl=trainControl(method=&quot;cv&quot;,number=3))</code></pre>
<pre><code>## Loading required package: randomForest</code></pre>
<pre><code>## Warning: package &#39;randomForest&#39; was built under R version 3.1.3</code></pre>
<pre><code>## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.
## 
## Attaching package: &#39;randomForest&#39;
## 
## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     margin</code></pre>
<pre class="r"><code>modFit</code></pre>
<pre><code>## Random Forest 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 9157, 9158, 9159 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD   Kappa SD   
##    2    0.9894444  0.9866465  0.0009114991  0.001154204
##   27    0.9873333  0.9839764  0.0021855063  0.002765403
##   52    0.9810000  0.9759665  0.0017915477  0.002268708
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>Once calculated, the final Random Forest model was then applied to the validation set. Based on the resulting confusion matrix, accuracy is roughly 99%. Based on this, we can assume that a similar accuracy can be attained when applied to the test set.</p>
<pre class="r"><code>pred&lt;-predict(modFit,validate)
confusionMatrix(pred,validate$classe)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1671   11    0    0    0
##          B    2 1127    6    0    0
##          C    0    1 1020   15    0
##          D    0    0    0  948    0
##          E    1    0    0    1 1082
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9937          
##                  95% CI : (0.9913, 0.9956)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.992           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9982   0.9895   0.9942   0.9834   1.0000
## Specificity            0.9974   0.9983   0.9967   1.0000   0.9996
## Pos Pred Value         0.9935   0.9930   0.9846   1.0000   0.9982
## Neg Pred Value         0.9993   0.9975   0.9988   0.9968   1.0000
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2839   0.1915   0.1733   0.1611   0.1839
## Detection Prevalence   0.2858   0.1929   0.1760   0.1611   0.1842
## Balanced Accuracy      0.9978   0.9939   0.9954   0.9917   0.9998</code></pre>
<p>While this accuracy is quite high (and Random Forest is known to provide relatively high accuracy), this result is slightly concerning as the model may be overfitted. Based on cursory evidence, it appears that certain predictors in the model may be less important than others. For example, roll_belt appears to be quite important for isolating class A while roll_arm, roll_dumbbell, and roll_forearm appear less important. Similar results are found for yaw data. In other words, additional analysis may be needed to extract the most meaningful predictors and therefore reduce the potential for overfitting.</p>
<pre class="r"><code>par(mfrow=c(2,2))
par(oma=c(0,0,2,0))
plot(train$classe,train$roll_belt, main=&quot;Roll Belt&quot;)
plot(train$classe,train$roll_arm, main=&quot;Roll Arm&quot;)
plot(train$classe,train$roll_dumbbell, main=&quot;Roll Dumbbell&quot;)
plot(train$classe,train$roll_forearm, main=&quot;Roll Forearm&quot;)
title(&quot;Figure 1: BoxPlots of Class vs. Roll Data&quot;, outer=TRUE)</code></pre>
<p><img src="project_files/figure-html/unnamed-chunk-8-1.png" title="" alt="" width="672" /></p>
<pre class="r"><code>par(mfrow=c(2,2))
par(oma=c(0,0,2,0))
plot(train$classe,train$pitch_belt, main=&quot;Pitch Belt&quot;)
plot(train$classe,train$pitch_arm, main=&quot;Pitch Arm&quot;)
plot(train$classe,train$pitch_dumbbell, main=&quot;Pitch Dumbbell&quot;)
plot(train$classe,train$pitch_forearm, main=&quot;Pitch Forearm&quot;)
title(&quot;Figure 2: BoxPlots of Class vs. Pitch Data&quot;, outer=TRUE)</code></pre>
<p><img src="project_files/figure-html/unnamed-chunk-9-1.png" title="" alt="" width="672" /></p>
<pre class="r"><code>par(mfrow=c(2,2))
par(oma=c(0,0,2,0))
plot(train$classe,train$yaw_belt, main=&quot;Yaw Belt&quot;)
plot(train$classe,train$yaw_arm, main=&quot;Yaw Arm&quot;)
plot(train$classe,train$yaw_dumbbell, main=&quot;Yaw Dumbbell&quot;)
plot(train$classe,train$yaw_forearm, main=&quot;Yaw Forearm&quot;)
title(&quot;Figure 3: BoxPlots of Class vs. Yaw Data&quot;, outer=TRUE)</code></pre>
<p><img src="project_files/figure-html/unnamed-chunk-10-1.png" title="" alt="" width="672" /></p>
<p>The following plot depicts the relative importance of roll_belt and yaw_belt as predictors, as class A is generally clustered in two separate areas.</p>
<pre class="r"><code>qplot(train$yaw_belt,train$roll_belt,col=classe,data=train,main=&quot;Figure 4: Roll Belt Data vs. Yaw Belt Data&quot;)</code></pre>
<p><img src="project_files/figure-html/unnamed-chunk-11-1.png" title="" alt="" width="672" /></p>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>In this study, six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different ways: class A is the correct way, while classes B-E are incorrect ways. The goal is to predict which class the subject falls into based on various accelerometer data collected by wearable devices. I applied a simple Random Forest model with 3-fold cross-validation to a training dataset to predict a class outcome. Given the high accuracy of the model in predicting the manner in which subjects performed the weight-lifting exercise (99%), it is not necessary to combine other models to improve accuracy (ensembling). However, the high accuracy may mean that the model is overfitted which may negatively impact out-of-sample performance. Additional analysis may be required to make the model more parsimonious which may ultimately improve out-of-sample performance.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
